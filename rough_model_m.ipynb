{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a222ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from acquire_c import *\n",
    "from prepare_c import *\n",
    "from explore_c import *\n",
    "from model_m import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f4e02",
   "metadata": {},
   "source": [
    "## Acquire data and find the dominant language in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebd99db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You can pass a threshold argument but the default is 75\n",
    "df = get_readme_data(lang = 'python', lang_threshold= 75, z_cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e78ce517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'python'\n",
    "not_lang = f'not_{lang}'\n",
    "# df['label']  = df.prog_lang.apply(lambda x: lang_or_not(x, lang))\n",
    "java_obj = NLP_explore(df, 'label', 'cleaned', lang, not_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa537e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b32290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e45b97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prog_lang</th>\n",
       "      <th>original</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Python</td>\n",
       "      <td>game this game is done by python</td>\n",
       "      <td>game game done python</td>\n",
       "      <td>python</td>\n",
       "      <td>game game done python</td>\n",
       "      <td>game game done python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Python</td>\n",
       "      <td>Attendance-provider Make a attendance in a exc...</td>\n",
       "      <td>make excel file screenshot google</td>\n",
       "      <td>python</td>\n",
       "      <td>make excel file screenshot googl</td>\n",
       "      <td>make excel file screenshot google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Python</td>\n",
       "      <td>Open-cv-tutorial All the function for open cv</td>\n",
       "      <td>function open</td>\n",
       "      <td>python</td>\n",
       "      <td>function open</td>\n",
       "      <td>function open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python Text App Using Twilio API With a free T...</td>\n",
       "      <td>python text app using api free account get tex...</td>\n",
       "      <td>python</td>\n",
       "      <td>python text app use api free account get text ...</td>\n",
       "      <td>python text app using api free account get tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Python</td>\n",
       "      <td>Real-Time Voice Cloning This repository is an ...</td>\n",
       "      <td>realtime repository implementation works realt...</td>\n",
       "      <td>python</td>\n",
       "      <td>realtim repositori implement work realtim feel...</td>\n",
       "      <td>realtime repository implementation work realti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prog_lang                                           original  \\\n",
       "18    Python                   game this game is done by python   \n",
       "23    Python  Attendance-provider Make a attendance in a exc...   \n",
       "24    Python      Open-cv-tutorial All the function for open cv   \n",
       "27    Python  Python Text App Using Twilio API With a free T...   \n",
       "29    Python  Real-Time Voice Cloning This repository is an ...   \n",
       "\n",
       "                                              cleaned   label  \\\n",
       "18                              game game done python  python   \n",
       "23                  make excel file screenshot google  python   \n",
       "24                                      function open  python   \n",
       "27  python text app using api free account get tex...  python   \n",
       "29  realtime repository implementation works realt...  python   \n",
       "\n",
       "                                              stemmed  \\\n",
       "18                              game game done python   \n",
       "23                   make excel file screenshot googl   \n",
       "24                                      function open   \n",
       "27  python text app use api free account get text ...   \n",
       "29  realtim repositori implement work realtim feel...   \n",
       "\n",
       "                                           lemmatized  \n",
       "18                              game game done python  \n",
       "23                  make excel file screenshot google  \n",
       "24                                      function open  \n",
       "27  python text app using api free account get tex...  \n",
       "29  realtime repository implementation work realti...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54095677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP_model():\n",
    "    ''' Creates classification models using a variety of Sklearn models.\n",
    "\n",
    "        Methods:\n",
    "        ----------------------------------------------------------------\n",
    "        > split: preforms train/test split. Can also preform X/y split if given a target array.\n",
    "        \n",
    "        > tf: gets the term frequency of the lemmatized column of the dataframe.\n",
    "        \n",
    "        > tf_idf: gets the term frequency-inverse document frequency \n",
    "        ----------------------------------------------------------------\n",
    "        \n",
    "        Arguments:\n",
    "            - data: Pandas DataFrame\n",
    "            - classifiers: List of classification models\n",
    "            - names: Names of classification models\n",
    "            - lang: Specifies a language to create a lang/not_lang label from\n",
    "            - top_langs: Specifies the top n langs to create labels for, non-top_langs will be labeled 'other'\n",
    "    '''\n",
    "    def __init__(self, data:pd.DataFrame, classifiers: list, names: list, lang = None, top_langs = None):\n",
    "        ''' Passes dataframe, list of actual classifiers and their names, as well as checks \n",
    "            for kwargs lang or top_lang\n",
    "            Creates a zip of classifiers and their names\n",
    "        '''\n",
    "        # Creating class instance of df\n",
    "        self.df = data.copy(deep = True)\n",
    "        \n",
    "        #Checking for individual language specified or n_langs and creating label column\n",
    "        # For individual lang specification\n",
    "        if lang != None and top_langs == None: # Checking for lang\n",
    "            self.lang = lang # assigning lang attribute\n",
    "            # creating label column\n",
    "            self.df['label'] = self.df.prog_lang.apply(lambda x: x.lower() if x == self.lang else f'not_{self.lang.lower()}')\n",
    "        if top_langs != None and lang == None: # Checking for top_langs\n",
    "            self.top_langs = self.df.prog_lang.value_counts()[:top_langs] # getting top n langs\n",
    "            # Creating labels column from top n languages            \n",
    "            self.df['label'] = self.df.prog_lang.apply(lambda x: x.lower() if x in self.top_langs else 'other')\n",
    "        if lang != None and top_langs != None:\n",
    "            raise AttributeError('Must specify either lang or top_langs, cant create labels for both.')\n",
    "        if top_langs != None and top_langs < 2:\n",
    "            raise AttributeError(\"Must specify more than one lang, if you want to check for a single language, use lang argument instead.\")\n",
    "        \n",
    "        # Clean dataframe\n",
    "        self.df.lemmatized = self.df.lemmatized.apply(basic_clean)\n",
    "        \n",
    "        # Creating class attributes\n",
    "        self.classifiers = classifiers\n",
    "        self.names = names\n",
    "        \n",
    "        models = {'models': (names, classifiers)} # creating dict models and names\n",
    "        self.models = models\n",
    "        \n",
    "    def split(self, df, target = None):\n",
    "        '''\n",
    "        This function takes in a dataframe and, optionally, a target_var array. Performs a train,\n",
    "        test split with no stratification. Returns train and test dfs.\n",
    "        '''\n",
    "        \n",
    "        # Checking for y specified\n",
    "        if target is None: # if no y, preform regular train, validate, test split\n",
    "            train, test = train_test_split(df, test_size=.2, \n",
    "                                          random_state=1312)\n",
    "            \n",
    "            self.train, self.test = train, test # setting self versions of each df\n",
    "            return train, test\n",
    "        \n",
    "        # If y is specified preform X/y train, validate, test split\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=.2, random_state=1312)\n",
    "            self.X_train, self.X_test,\\\n",
    "            self.y_train, self.y_test = X_train, X_test, y_train, y_test # attributes for each X/y df and array\n",
    "            \n",
    "            return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def tf(self):\n",
    "        ''' Gets the term frequency of lematized column in the df and returns\n",
    "            a dataframe with raw value_counts, frequency, and augmented frequency\n",
    "        '''\n",
    "        \n",
    "        # For each lemmatized doc, append to series\n",
    "        docs = [] # init empty series for split documents\n",
    "        words = [] # init empty series for unique words\n",
    "        for doc in self.df['lemmatized'].values:\n",
    "            for word in doc.split(): # iterating through each word in a split doc\n",
    "                words.append(word) # add to words\n",
    "        \n",
    "        word_ser = pd.Series(words) # turn w\n",
    "        \n",
    "        # Creating a df from unique words containing raw term count, \n",
    "        tf_df = (pd.DataFrame({'raw_count': word_ser.value_counts()})) # raw counts of each term\n",
    "        tf_df['frequency'] = tf_df.raw_count / tf_df.raw_count.sum() # frequency of each term\n",
    "        tf_df['augmented_frequency'] = tf_df.frequency / tf_df.frequency.max() # augmented freq of words\n",
    "        \n",
    "        return tf_df\n",
    "    \n",
    "    def tf_idf(self):\n",
    "        ''' Gets tf_idf and returns the dataframe of TfidVectorizer\n",
    "        '''\n",
    "        tfidf = TfidfVectorizer() # Make the opbject\n",
    "        bag_of_words = tfidf.fit_transform(self.df['lemmatized'].values) # Fit_transform on lemmatized\n",
    "        tfidf_df = pd.DataFrame(bag_of_words.todense(), columns=tfidf.get_feature_names()) # Wrapping in a dataframe\n",
    "        return tfidf_df\n",
    "    \n",
    "    def count_vectorize(self, ngram_range = (1,1)):\n",
    "        ''' Preforms a count vectorizeation with ngrams of n length.\n",
    "            WARNING: If not cached on system can take a long time to process, \n",
    "            creates a cacehd csv for faster use in future iterations.\n",
    "        '''\n",
    "        # Checking for cached vectorized csv\n",
    "        print('''Creating vectorized dataframe now. Vectorization may take a while, please wait...''')\n",
    "        \n",
    "        # Using Bag of Words count vectorizer for hexamers\n",
    "        cv = CountVectorizer(ngram_range=(1,1)) # make the object\n",
    "        vectors = cv.fit_transform(self.df.lemmatized.values) # fit_transform on lemmatized col\n",
    "        self.vocab_count = cv.vocabulary_\n",
    "        \n",
    "        # Wraps vectorized array in a dataframe with feature names as the columns\n",
    "        vector_df = pd.DataFrame(vectors.todense(), columns = cv.get_feature_names())\n",
    "                \n",
    "        # assigning vectorized dataframe as an attribute\n",
    "        self.vectorized = vector_df.copy()\n",
    "        \n",
    "        return vector_df\n",
    "        \n",
    "    \n",
    "    def metrics(self, metric_type = 'accuracy', splits = 3):\n",
    "        ''' Checks for and encodes label column\n",
    "            Creates a metrics df measuring metric_type, accuracy by default.\n",
    "            Preforms a kfold a number of times determined by splits.\n",
    "        '''\n",
    "        try: # checking if label exists, if not raise KeyError, didnt specify a lang or top_langs\n",
    "            self.df['label']\n",
    "        except KeyError:\n",
    "            return KeyError('Must specify language target in class to create models')\n",
    "        \n",
    "        try: # Checking if vectorization has already run, if yes there will be an attribute vectorized df\n",
    "            self.vectorized\n",
    "        except AttributeError: # If no vectorized attribute exists get vectorized df calling self.count_vectorize\n",
    "            print('Have not run count_vectorize method yet, running now...')\n",
    "            self.vectorized = self.count_vectorize()\n",
    "            print('All done! Moving on to modeling, this may take a while...')\n",
    "        target = 'label' # Setting target to label\n",
    "        \n",
    "        # checking for lang or top_langs\n",
    "        if self.df[target].nunique() == 2: # If one lang chosen\n",
    "            s = self.df[target].replace([f'{self.lang.lower()}', f'not_{self.lang.lower()}'], [1,0]) # Endode lang as 1 not_lang as 0\n",
    "        else: # if top_langs\n",
    "            lang_list = [l.lower() for l in list(self.top_langs.index)] # getting a list of all lower case langs in top lang\n",
    "            lang_list.append('other') # appending 'other' label\n",
    "            \n",
    "            lang_encode = list(range(1, len(self.top_langs)+1)) # list of numbers to encode top_langs as\n",
    "            lang_encode.append(0) # appending 0 for other\n",
    "            s = self.df[target].replace(lang_list, lang_encode) # encoding top_langs\n",
    "            \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.split(self.vectorized, s)\n",
    "        \n",
    "        result = [] # init empty results list\n",
    "        for model in self.models['models']: # iterate through zipped models\n",
    "            kfold = KFold(n_splits = splits) # number of kfolds set to splits\n",
    "            scores = cross_validate(classifier, X_train, y_train, cv = kfold, scoring = metric_type, return_estimator=True) # cross validate on each kfold\n",
    "            result.append(scores) # append to results\n",
    "            \n",
    "            msg = \"{0}: Validate accuracy: {1}\".format(name, scores['test_score'].mean())\n",
    "            print(msg)\n",
    "        \n",
    "        estimators = [res['estimator'] for res in result]\n",
    "        results = [res['test_score'] for res in result]\n",
    "        avg_res = [round(res['test_score'].mean(), 4) * 100 for res in result] # list comp to get mean of cross val tests for each model\n",
    "        metrics_df = pd.DataFrame(data = zip(self.names, avg_res), columns = ['model', f'average_{metric_type}%']) # wrap zipped model names and results in dataframe\n",
    "        \n",
    "        \n",
    "        return metrics_df.sort_values(by = [f'average_{metric_type}%'], ascending = False), zip(estimators, results) # return sorted by metric\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04ebb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['K Nearest Neighbors', 'Decision Tree', 'Random Forest', \n",
    "         'Gaussian N-Bayes', 'Multinomial N-Bayes']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 6),\n",
    "    DecisionTreeClassifier(max_depth = 7),\n",
    "    RandomForestClassifier(n_estimators = 10),\n",
    "    GaussianNB(),\n",
    "    MultinomialNB(alpha = .5)\n",
    "    ]\n",
    "\n",
    "model_obj = NLP_model(df, classifiers, names, lang = 'Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc197b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(n_neighbors=6),\n",
       " DecisionTreeClassifier(max_depth=7),\n",
       " RandomForestClassifier(n_estimators=10),\n",
       " GaussianNB(),\n",
       " MultinomialNB(alpha=0.5)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.models['models'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b3e0955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have not run count_vectorize method yet, running now...\n",
      "Creating vectorized dataframe now. Vectorization may take a while, please wait...\n",
      "All done! Moving on to modeling, this may take a while...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-8861542b643a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetric_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetric_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-b26ae0a689ac>\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self, metric_type, splits)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# init empty results list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate through zipped models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of kfolds set to splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cross validate on each kfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "metric_df, models_zip = model_obj.metrics(splits = 10)\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71005034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6),\n",
       "   KNeighborsClassifier(n_neighbors=6)],\n",
       "  array([0.8031968 , 0.81018981, 0.83316683, 0.82617383, 0.82617383,\n",
       "         0.807     , 0.826     , 0.817     , 0.823     , 0.835     ])),\n",
       " ([DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7),\n",
       "   DecisionTreeClassifier(max_depth=7)],\n",
       "  array([0.85714286, 0.86013986, 0.86113886, 0.86513487, 0.86913087,\n",
       "         0.865     , 0.884     , 0.838     , 0.869     , 0.875     ])),\n",
       " ([RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10),\n",
       "   RandomForestClassifier(n_estimators=10)],\n",
       "  array([0.9040959 , 0.89310689, 0.91308691, 0.90909091, 0.8951049 ,\n",
       "         0.902     , 0.913     , 0.887     , 0.897     , 0.897     ])),\n",
       " ([GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB(),\n",
       "   GaussianNB()],\n",
       "  array([0.8961039 , 0.88911089, 0.8971029 , 0.90809191, 0.88111888,\n",
       "         0.876     , 0.899     , 0.888     , 0.91      , 0.888     ])),\n",
       " ([MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5),\n",
       "   MultinomialNB(alpha=0.5)],\n",
       "  array([0.9030969 , 0.90609391, 0.92607393, 0.92007992, 0.91008991,\n",
       "         0.917     , 0.931     , 0.917     , 0.911     , 0.918     ]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c01d80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ae8d75d2432c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7acb051f",
   "metadata": {},
   "source": [
    "## Modeling Performance:\n",
    "### JavaScript\n",
    "##### Hyperparams:\n",
    "- KNeighborsClassifier(n_neighbors = 3),\n",
    "- DecisionTreeClassifier(max_depth = 5),\n",
    "- RandomForestClassifier(max_depth = 5, n_estimators = 10, max_features = 1 ),\n",
    "- GaussianNB(),\n",
    "- MultinomialNB()\n",
    "\n",
    "\n",
    "> #### First iteration: (75% threshold, no zscore)\n",
    "> - K Nearest Neighbors: Accuracy: 0.4437958746786057\n",
    "> - Decision Tree: Accuracy: 0.5243970413600353\n",
    "> - Random Forest: Accuracy: 0.3019957833163259\n",
    "> - Gaussian N-Bayes: Accuracy: 0.43499919463886333\n",
    "> - Multinomial N-Bayes: Accuracy: 0.5169951603916912\n",
    "\n",
    "> #### Second Iteration (75% lang threshold, zscore .5)\n",
    "> - K Nearest Neighbors: Accuracy: 0.42000479731350443\n",
    "> - Decision Tree: Accuracy: 0.6441992484208843\n",
    "> - Random Forest: Accuracy: 0.6461981290477333\n",
    "> - Gaussian N-Bayes: Accuracy: 0.5742384264811705\n",
    "> - Multinomial N-Bayes: Accuracy: 0.6247701287279124\n",
    "\n",
    "> #### Third Iteration (100% lang threshold, zscore .5)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.8817125081859856\n",
    "> - Decision Tree: Validate accuracy: 0.9279783272817043\n",
    "> - Random Forest: Validate accuracy: 0.8400252694089291\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.9172856871827753\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9334353652863924\n",
    "\n",
    "> #### Fourth Iteration (100% lang threshold, zscore .5, KFolds = 10)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.8886948083454633\n",
    "> - Decision Tree: Validate accuracy: 0.9277563718354882\n",
    "> - Random Forest: Validate accuracy: 0.8400267336434817\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.9172855362426388\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9351794769339079\n",
    "\n",
    "##### Hyperparams:\n",
    "- MultinomialNB(alpha = .5)\n",
    "\n",
    "> #### Best Model Iteration: (100% lang threshold, zscore .5, KFolds = 10)\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9412896842385668\n",
    "\n",
    "### Python:\n",
    "##### Hyperparams:\n",
    "- KNeighborsClassifier(n_neighbors = 6),\n",
    "- DecisionTreeClassifier(max_depth = 7),\n",
    "- RandomForestClassifier(n_estimators = 10),\n",
    "- GaussianNB(),\n",
    "- MultinomialNB(alpha = .5)\n",
    "\n",
    "> #### First iteration: (75% threshold, no zscore)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.8206901098901099\n",
    "> - Decision Tree: Validate accuracy: 0.8648681318681319\n",
    "> - Random Forest: Validate accuracy: 0.9007505494505494\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.8932528471528471\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9159434565434564\n",
    "\n",
    "> #### Second iteration: (75% threshold, zscore .5)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.8206901098901099\n",
    "> - Decision Tree: Validate accuracy: 0.8635692307692308\n",
    "> - Random Forest: Validate accuracy: 0.8984497502497503\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.8932528471528471\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9159434565434564\n",
    "\n",
    "> #### Third iteration: (100% threshold, zscore .5)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.7704337190524877\n",
    "> - Decision Tree: Validate accuracy: 0.8218125615128089\n",
    "> - Random Forest: Validate accuracy: 0.8699010061823358\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.8718856602295204\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.885873792437866\n",
    "\n",
    "> #### Fourth iteration: (90% threshold, zscore .5)\n",
    "> - K Nearest Neighbors: Validate accuracy: 0.7991583768344331\n",
    "> - Decision Tree: Validate accuracy: 0.8479582389441545\n",
    "> - Random Forest: Validate accuracy: 0.8916349847335763\n",
    "> - Gaussian N-Bayes: Validate accuracy: 0.8852309662168818\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9072623855018221\n",
    "\n",
    "##### Hyperparams:\n",
    "- MultinomialNB(alpha = .5)\n",
    "\n",
    "> #### Best Model Iteration: (75% threshold, zscore .5)\n",
    "> - Multinomial N-Bayes: Validate accuracy: 0.9138447552447554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aeefb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ee614c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>25128</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>20312</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.808341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>19874</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.790911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>19795</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.787767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>18964</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.754696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invalidation</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multilingual</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3296 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              raw_count  frequency  augmented_frequency\n",
       "data              25128   0.008218             1.000000\n",
       "use               20312   0.006643             0.808341\n",
       "gt                19874   0.006500             0.790911\n",
       "yes               19795   0.006474             0.787767\n",
       "project           18964   0.006202             0.754696\n",
       "...                 ...        ...                  ...\n",
       "invalidation        100   0.000033             0.003980\n",
       "convolution         100   0.000033             0.003980\n",
       "ranking             100   0.000033             0.003980\n",
       "multilingual        100   0.000033             0.003980\n",
       "320                 100   0.000033             0.003980\n",
       "\n",
       "[3296 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f195c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>0527</th>\n",
       "      <th>0528</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtubedl</th>\n",
       "      <th>youve</th>\n",
       "      <th>zappa</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12507 rows × 3264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00   01   02   03   04   05  0527  0528   06   07  ...  youll  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...   ...   ...  ...  ...  ...    ...   \n",
       "12502  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "12503  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "12504  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "12505  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "12506  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "          youre  youtube  youtubedl     youve  zappa  zero  zip  zoom  zsh  \n",
       "0      0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "1      0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "2      0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "3      0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "4      0.200226      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "...         ...      ...        ...       ...    ...   ...  ...   ...  ...  \n",
       "12502  0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "12503  0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "12504  0.078921      0.0        0.0  0.025644    0.0   0.0  0.0   0.0  0.0  \n",
       "12505  0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "12506  0.000000      0.0        0.0  0.000000    0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[12507 rows x 3264 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.tf_idf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
