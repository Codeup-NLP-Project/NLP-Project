{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a222ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from acquire_c import *\n",
    "from prepare_c import *\n",
    "from explore_c import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f4e02",
   "metadata": {},
   "source": [
    "## Acquire data and find the dominant language in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ebd99db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can pass a threshold argument but the default is 75\n",
    "df = get_readme_data()\n",
    "ongoing_stopwords = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_or_not(s:str, lang:str) -> str:\n",
    "    '''Takes string and returns if it is java or not java\n",
    "    '''\n",
    "    if s.lower() == lang:\n",
    "        return lang\n",
    "    return f'not_{lang}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ce517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'javascript'\n",
    "not_lang = f'not_{lang}'\n",
    "df['label']  = df.prog_lang.apply(lambda x: lang_or_not(x, lang))\n",
    "java_obj = NLP_explore(df, 'label', 'cleaned', lang, not_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eab665",
   "metadata": {},
   "source": [
    "## Explore\n",
    "\n",
    "### Look at word freqencies for JavaScript\n",
    "|          |   word_count |\n",
    "|:---------|-------------:|\n",
    "| data     |        25128 |\n",
    "| use      |        20312 |\n",
    "| gt       |        19874 |\n",
    "| yes      |        19795 |\n",
    "| code     |        18020 |\n",
    "| python   |        17961 |\n",
    "| using    |        17762 |\n",
    "| top      |        16057 |\n",
    "| project  |        15087 |\n",
    "| 1        |        13589 |\n",
    "| run      |        13366 |\n",
    "| api      |        12797 |\n",
    "| unknown  |        12742 |\n",
    "| github   |        12660 |\n",
    "| file     |        12109 |\n",
    "| learning |        11736 |\n",
    "| open     |        11354 |\n",
    "| app      |        11260 |\n",
    "| create   |        10836 |\n",
    "| 2        |        10439 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4495fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame({'word_count': java_obj.all_freq}).head(20).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbbbe7",
   "metadata": {},
   "source": [
    "## Look at some word count visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at just JavaScript hplot\n",
    "java_obj.hplot_word_freq_viz(n=5, sort=lang)\n",
    "# Looking at just JavaScript bplot stacked\n",
    "java_obj.stacked_bplot_freq(n=5, sort=not_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a558e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at just not_JavaScript hplot\n",
    "java_obj.hplot_word_freq_viz(n=5, sort=lang)\n",
    "# Looking at just not_JavaScript bplot stacked\n",
    "java_obj.stacked_bplot_freq(n=5, sort=not_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc91068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at just all hplot\n",
    "java_obj.hplot_word_freq_viz(n=5)\n",
    "# Looking at just all bplot stacked\n",
    "java_obj.stacked_bplot_freq(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729036f",
   "metadata": {},
   "source": [
    "## Look at N-Grams Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b8fe0",
   "metadata": {},
   "source": [
    "### Look at Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_bigram = java_obj.n_gram(top_n= 10, col=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9028bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_java_bigram = java_obj.n_gram(top_n = 10, col=not_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_bigrams = java_obj.n_gram(top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb9b76",
   "metadata": {},
   "source": [
    "### Look at trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d07b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_trigram = java_obj.n_gram(n=3, top_n=10, col=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_java_trigram = java_obj.n_gram(n=3, top_n=10, col=not_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd76969",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trigram = java_obj.n_gram(n=3, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbafb181",
   "metadata": {},
   "source": [
    "### Plot some wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_obj.plot_wordcloud(col=lang, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_obj.plot_wordcloud(col=not_lang, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_obj.plot_wordcloud(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714bb9e",
   "metadata": {},
   "source": [
    "## Add some sentiment analysis and some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sentiment analysis\n",
    "java_obj.add_sentiment_analysis()\n",
    "# Add features\n",
    "java_obj.add_features()\n",
    "\n",
    "java_obj.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82605f1",
   "metadata": {},
   "source": [
    "## Sentiment analysis bivariate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_obj.sentiment_bivariate_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f775d90",
   "metadata": {},
   "source": [
    "## Sentiment distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_obj.sentiment_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ae05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a59ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469aec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04aa537e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b32290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95aa08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66237290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP_model():\n",
    "    ''' Creates classification models using a variety of Sklearn models.\n",
    "\n",
    "        Models:\n",
    "        ----------------------------------------------------------------\n",
    "        KNeighborsClassifier, DecisionTreeClassifier, svm, GaussianNB, \n",
    "        MultinomialNB, GaussianProcessClassifier, MLPClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "        ----------------------------------------------------------------\n",
    "        \n",
    "        Arguments:\n",
    "            - data: Pandas DataFrame\n",
    "            - classifiers: List of classification models\n",
    "            - names: Names of classification models\n",
    "            - lang: Specifies a language to create a lang/not_lang label from\n",
    "            - top_langs: Specifies the top n langs to create labels for, non-top_langs will be labeled 'other'\n",
    "    '''\n",
    "    def __init__(self, data:pd.DataFrame, classifiers: list, names: list, lang = None, top_langs = None):\n",
    "        ''' Passes dataframe, list of actual classifiers and their names, as well as checks \n",
    "            for kwargs lang or top_lang\n",
    "            Creates a zip of classifiers and their names\n",
    "        '''\n",
    "        # Creating class instance of df\n",
    "        self.df = data.copy(deep = True)\n",
    "        \n",
    "        #Checking for individual language specified or n_langs and creating label column\n",
    "        # For individual lang specification\n",
    "        if lang != None and top_langs == None: # Checking for lang\n",
    "            self.lang = lang # assigning lang attribute\n",
    "            # creating label column\n",
    "            self.df['label'] = self.df.prog_lang.apply(lambda x: x.lower() if x == self.lang else f'not_{self.lang.lower()}')\n",
    "        if top_langs != None and lang == None: # Checking for top_langs\n",
    "            self.top_langs = self.df.prog_lang.value_counts()[:top_langs] # getting top n langs\n",
    "            # Creating labels column from top n languages            \n",
    "            self.df['label'] = self.df.prog_lang.apply(lambda x: x.lower() if x in self.top_langs else 'other')\n",
    "        if lang != None and top_langs != None:\n",
    "            raise AttributeError('Must specify either lang or top_langs, cant create labels for both.')\n",
    "        if top_langs != None and top_langs < 2:\n",
    "            raise AttributeError(\"Must specify more than one lang, if you want to check for a single language, use lang argument instead.\")\n",
    "        \n",
    "        # Clean dataframe\n",
    "        self.df.lemmatized = self.df.lemmatized.apply(basic_clean)\n",
    "        \n",
    "        # Creating class attributes\n",
    "        self.classifiers = classifiers\n",
    "        self.names = names\n",
    "        \n",
    "        models = zip(names, classifiers) # zipping models and names\n",
    "        self.models = models\n",
    "        \n",
    "    def split(self, target = None):\n",
    "        '''\n",
    "        This function takes in a dataframe and, optionally, a target_var array. Performs a train, validate, \n",
    "        test split with no stratification. Returns train, validate, and test dfs.\n",
    "        '''\n",
    "        \n",
    "        # Checking for y specified\n",
    "        if target is None: # if no y, preform regular train, validate, test split\n",
    "            train_validate, test = train_test_split(self.df, test_size=.2, \n",
    "                                                    random_state=1312)\n",
    "            train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                                    random_state=1312)\n",
    "            \n",
    "            self.train, self.validate, self.test = train, validate, test # setting self versions of each df\n",
    "            return train, validate, test\n",
    "        \n",
    "        # If y is specified preform X/y train, validate, test split\n",
    "        else:\n",
    "            X_train_validate, X_test, y_train_validate, y_test = train_test_split(self.df.drop(columns = target), \n",
    "                                                                            self.df[target],\n",
    "                                                                            test_size=.2, \n",
    "                                                                            random_state=1312)\n",
    "            X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate,\n",
    "                                                                            test_size=.3, \n",
    "                                                                            random_state=1312)\n",
    "            self.X_train, self.X_validate, self.X_test,\\\n",
    "            self.y_train, self.y_validate, self.y_test = X_train, X_validate, X_test, y_train,\\\n",
    "                                                        y_validate, y_test # attributes for each X/y df and array\n",
    "            \n",
    "            return X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "    \n",
    "    \n",
    "    def tf(self):\n",
    "        ''' Gets the term frequency of lematized column in the df\n",
    "        '''\n",
    "        \n",
    "        # For each lemmatized doc, append to series\n",
    "        docs = [] # init empty series for split documents\n",
    "        words = [] # init empty series for unique words\n",
    "        for doc in self.df['lemmatized'].values:\n",
    "            for word in doc.split(): # iterating through each word in a split doc\n",
    "                words.append(word) # add to words\n",
    "        \n",
    "        word_ser = pd.Series(words) # turn w\n",
    "        \n",
    "        # Creating a df from unique words containing raw term count, \n",
    "        tf_df = (pd.DataFrame({'raw_count': word_ser.value_counts()})) # raw counts of each term\n",
    "        tf_df['frequency'] = tf_df.raw_count / tf_df.raw_count.sum() # frequency of each term\n",
    "        tf_df['augmented_frequency'] = tf_df.frequency / tf_df.frequency.max() # augmented freq of words\n",
    "        \n",
    "        return tf_df\n",
    "    \n",
    "    def idf(self):\n",
    "        ''' Gets the inverse document frequency of the lemmatized column\n",
    "        '''\n",
    "        \n",
    "#         top_n = list(self.tf().head().index)\n",
    "        \n",
    "#         docs = [] # init empty series for split documents\n",
    "#         words = [] # init empty series for unique words\n",
    "#         for doc in self.df['lemmatized'].values:\n",
    "#             for word in doc.split(): # iterating through each word in a split doc\n",
    "#                 words.append(word) # add to words\n",
    "        \n",
    "#         n_occurences = []\n",
    "#         for doc in self.df['lemmatized'].values:\n",
    "            \n",
    "            \n",
    "#         unique_words = pd.Series(' '.join(words.unique()))\n",
    "#         return len(documents) / n_occurences\n",
    "    \n",
    "    def tf_idf(self):\n",
    "        return 'Yet to make method'\n",
    "    \n",
    "    \n",
    "    def count_vectorize(self, ngram_range = (1,1)):\n",
    "        ''' Preforms a count vectorizeation with ngrams of n length.\n",
    "            WARNING: If not caced on system can take a long time to process, \n",
    "            creates a cacehd csv for faster use in future iterations.\n",
    "        '''\n",
    "        # Checking for cached vectorized csv\n",
    "        filename = 'Vectorized.csv'\n",
    "        if os.path.isfile(filename):\n",
    "            print('Vectorized.csv already exists on your machine! Pulling it now...')\n",
    "            vector_df = pd.read_csv(filename)\n",
    "        else:\n",
    "            print('''Vectorized.csv does not exist on your local machine! Creating vectorized csv and dataframe now. \n",
    "                  Vectorization may take a while, please wait...''')\n",
    "            # Using Bag of Words count vectorizer for hexamers\n",
    "            cv = CountVectorizer(ngram_range=(1,1)) # make the object\n",
    "            vectors = cv.fit_transform(self.df.lemmatized.values) # fit_transform on lemmatized col\n",
    "            self.vocab_count = cv.vocabulary_\n",
    "            # Wraps vectorized array in a dataframe with feature names as the columns\n",
    "            vector_df = pd.DataFrame(vectors.todense(), columns = cv.get_feature_names())\n",
    "            return vector_df\n",
    "        \n",
    "        # assigning vectorized dataframe as an attribute\n",
    "        self.vectorized = vector_df.copy()\n",
    "        \n",
    "        return vector_df\n",
    "        \n",
    "    \n",
    "    def metrics(self, metric_type = 'accuracy', splits = 3):\n",
    "        ''' Checks for and encodes label column\n",
    "            Creates a metrics df measuring metric_type, accuracy by default.\n",
    "            Preforms a kfold a number of times determined by splits.\n",
    "        '''\n",
    "        try: # checking if label exists, if not raise KeyError, didnt specify a lang or top_langs\n",
    "            self.df['label']\n",
    "        except KeyError:\n",
    "            return KeyError('Must specify language target in class to create models')\n",
    "        \n",
    "        try: # Checking if vectorization has already run, if yes there will be an attribute vectorized df\n",
    "            self.vectorized\n",
    "        except AttributeError: # If no vectorized attribute exists get vectorized df calling self.count_vectorize\n",
    "            print('Have not run count_vectorize method yet, running now...')\n",
    "            self.vectorized = self.count_vectorize()\n",
    "            print('All done! Moving on to modeling, this may take a while...')\n",
    "        target = 'label' # Setting target to label\n",
    "        \n",
    "        # checking for lang or top_langs\n",
    "        if self.df[target].nunique == 2: # If one lang chosen\n",
    "            y_data = self.df[target].replace([f'{self.lang.lower()}', f'not_{self.lang.lower()}'], [1,0]) # Endode lang as 1 not_lang as 0\n",
    "        else: # if top_langs\n",
    "            lang_list = [l.lower() for l in list(self.top_langs.index)] # getting a list of all lower case langs in top lang\n",
    "            lang_list.append('other') # appending 'other' label\n",
    "            \n",
    "            lang_encode = list(range(1, len(self.top_langs)+1)) # list of numbers to encode top_langs as\n",
    "            lang_encode.append(0) # appending 0 for other\n",
    "            y_data = self.df[target].replace(lang_list, lang_encode) # encoding top_langs\n",
    "            \n",
    "            \n",
    "        result = [] # init empty results list\n",
    "        for (name, classifier) in self.models: # iterate through zipped models\n",
    "            kfold = KFold(n_splits = splits) # number of kfolds set to splits\n",
    "            scores = cross_validate(classifier, self.vectorized, y_data, cv = kfold, scoring = metric_type) # cross validate on each kfold\n",
    "            result.append(scores) # append to results\n",
    "            \n",
    "            msg = \"{0}: Accuracy: {1}\".format(name, scores['test_score'].mean())\n",
    "            print(msg)\n",
    "        \n",
    "        results = [res['test_score'].mean() for res in result] # list comp to get mean of cross val tests for each model\n",
    "        metrics_df = pd.DataFrame(data = zip(self.names, results), columns = ['model', metric_type]) # wrap zipped model names and results in dataframe\n",
    "        return metrics_df.sort_values(by = [metric_type], ascending = False) # return sorted by metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04ebb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['K Nearest Neighbors', 'Decision Tree', 'Random Forest', \n",
    "         'Gaussian N-Bayes', 'Multinomial N-Bayes']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    DecisionTreeClassifier(max_depth = 5),\n",
    "    RandomForestClassifier(max_depth = 5, n_estimators = 10, max_features = 1 ),\n",
    "    GaussianNB(),\n",
    "    MultinomialNB()\n",
    "    ]\n",
    "\n",
    "model_obj = NLP_model(df, classifiers, names, top_langs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "253df249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          1127\n",
       "Python              1022\n",
       "Jupyter Notebook     611\n",
       "Java                 428\n",
       "HTML                 340\n",
       "Name: prog_lang, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.top_langs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce30e9b",
   "metadata": {},
   "source": [
    "### Modeling Performance:\n",
    "> #### First iteration:\n",
    "> - K Nearest Neighbors: Accuracy: 0.4437958746786057\n",
    "> - Decision Tree: Accuracy: 0.5243970413600353\n",
    "> - Random Forest: Accuracy: 0.3019957833163259\n",
    "> - Gaussian N-Bayes: Accuracy: 0.43499919463886333\n",
    "> - Multinomial N-Bayes: Accuracy: 0.5169951603916912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "707949f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'gt', 'python', 'use', 'file']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_obj.tf().head(5).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca34e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized, vocab = model_obj.count_vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['wip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4945341",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized.T.iloc[207455].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized['data'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e150b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410830ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = model_obj.split(target = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858530e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11081b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_models(X_data, y_data, classifier_names, classifier_models):\n",
    "    '''\n",
    "        Takes two arrays:\n",
    "        - X_data = data without the target_var included\n",
    "        - y_data = an array of the target_var\n",
    "        - List of model names \n",
    "        - List of the classifiers themselves\n",
    "        \n",
    "        Preforms K-fold and cross-validation and returns a metrics dataframe with the model name and accuracy score. \n",
    "    '''\n",
    "    # Zipping models and Classifiers\n",
    "    models = zip(classifier_names, classifier_models)\n",
    "\n",
    "    # Init empty lists\n",
    "    names = [] \n",
    "    result = []\n",
    "    coeff = []\n",
    "\n",
    "    # Cross-validating accuracy for each model based on Train subset\n",
    "    for i, (name, model) in enumerate(models):\n",
    "        kfold = KFold(n_splits = 10)\n",
    "        scores = cross_validate(model, X_data, y_data, cv = kfold, scoring = 'accuracy', return_estimator=True)\n",
    "        result.append(scores)\n",
    "        names.append(name)\n",
    "        try:\n",
    "            coeff.append(model.coeff_)\n",
    "        except AttributeError:\n",
    "            coeff.append(None)\n",
    "        msg = \"{0}: Accuracy: {1}, Coeff: {2}\".format(name, scores['test_score'].mean(), coeff[i])\n",
    "        print(msg)\n",
    "        \n",
    "    results = [res['test_score'].mean() for res in result]\n",
    "    metrics_df = pd.DataFrame(data = zip(names, results), columns = ['Model', 'Accuracy'])\n",
    "    return metrics_df.sort_values(by = ['Accuracy'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24760107",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_models(X_train, y_train, names, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
